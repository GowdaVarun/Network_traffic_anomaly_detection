{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packet Classification & Anomaly Detection\n",
    "Use this notebook to load features exported by `detection.py` and classify/analyze packets using ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')\n",
    "\n",
    "RAW_CSV = \"captured_packets.csv\"\n",
    "CLEAN_CSV = \"cleaned_packets.csv\"\n",
    "JSON_OUTPUT = \"SCAM.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load captured packet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "\n",
    "def ip_to_int(ip):\n",
    "    try:\n",
    "        return int(ipaddress.IPv4Address(str(ip)))\n",
    "    except Exception:\n",
    "        return 0  # fallback for malformed IPs\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Remove 0.0.0.0 only if label is 'good'\n",
    "    if 'label' in df.columns:\n",
    "        df = df[~((df['src_ip'] == '0.0.0.0') & (df['label'].astype(str).str.lower() == 'good'))]\n",
    "        df = df[~((df['dst_ip'] == '0.0.0.0') & (df['label'].astype(str).str.lower() == 'good'))]\n",
    "\n",
    "    # Convert IPs to integers using ipaddress for robustness\n",
    "    df['src_ip'] = df['src_ip'].apply(ip_to_int)\n",
    "    df['dst_ip'] = df['dst_ip'].apply(ip_to_int)\n",
    "\n",
    "    # Encode protocol and flags\n",
    "    df['protocol'] = LabelEncoder().fit_transform(df['protocol'].astype(str))\n",
    "    df['flags'] = LabelEncoder().fit_transform(df['flags'].astype(str))\n",
    "\n",
    "    # Encode label: good=0, bad=1, fallback for already numeric\n",
    "    if df['label'].dtype == object or df['label'].dtype == 'str':\n",
    "        df['label'] = df['label'].astype(str).str.lower().map({\"good\": 0, \"bad\": 1}).fillna(df['label'])\n",
    "    df['label'] = pd.to_numeric(df['label'], errors='coerce').astype(int)\n",
    "\n",
    "    # Ensure numeric columns\n",
    "    for col in ['length', 'ttl', 'window_size', 'src_port', 'dst_port']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    df.to_csv(CLEAN_CSV, index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9961e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df):\n",
    "    features = ['src_ip', 'dst_ip', 'src_port', 'dst_port', 'protocol', 'flags', 'length', 'ttl', 'window_size']\n",
    "    X = df[features]\n",
    "    y = df['label']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    model = GradientBoostingClassifier(n_estimators=150, learning_rate=0.1, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    logging.info(\"\\n--- Model Evaluation ---\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9d23f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import logging\n",
    "\n",
    "def analyze_and_export(df, model, protocol_encoder=None):\n",
    "    features = ['src_ip', 'dst_ip', 'src_port', 'dst_port', 'protocol', 'flags', 'length', 'ttl', 'window_size']\n",
    "    df['predicted'] = model.predict(df[features])\n",
    "\n",
    "    total_packets = len(df)\n",
    "    anomalies = df[df['predicted'] == 1]\n",
    "    total_anomalies = len(anomalies)\n",
    "\n",
    "    anomalies_by_type = Counter(anomalies['predicted'])\n",
    "\n",
    "    # Protocol distribution counts (encoded)\n",
    "    proto_dist = df['protocol'].value_counts().to_dict()\n",
    "\n",
    "    # If you have a protocol_encoder (LabelEncoder) passed, decode keys for human-readable proto_dist\n",
    "    if protocol_encoder:\n",
    "        proto_dist = {protocol_encoder.inverse_transform([k])[0]: v for k, v in proto_dist.items()}\n",
    "\n",
    "    anomaly_ips = {\n",
    "        \"1\": anomalies['src_ip'].astype(str).unique().tolist(),\n",
    "        \"2\": [],\n",
    "        \"3\": []\n",
    "    }\n",
    "\n",
    "    anomalies_last_seen = {\n",
    "        \"1\": anomalies['timestamp'].max() if not anomalies.empty else None\n",
    "    }\n",
    "\n",
    "    summary = {\n",
    "        \"total_packets\": total_packets,\n",
    "        \"total_anomalies\": total_anomalies,\n",
    "        \"anomalies_by_type\": dict(anomalies_by_type),\n",
    "        \"anomaly_ips\": anomaly_ips,\n",
    "        \"protocol_distribution\": proto_dist,\n",
    "        \"anomalies_last_seen\": anomalies_last_seen\n",
    "    }\n",
    "\n",
    "    with open(JSON_OUTPUT, 'w') as f:\n",
    "        json.dump(summary, f, indent=4, default=str)\n",
    "\n",
    "    logging.info(f\"Summary saved to {JSON_OUTPUT}\")\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81a4b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def notify_admin():\n",
    "#     \"\"\"Notify administrators about detected network anomalies via email\"\"\"\n",
    "#     try:\n",
    "#         import Email  # Import the Email.py module\n",
    "#         success = Email.trigger_email()\n",
    "#         if success:\n",
    "#             logging.info(\"Alert email triggered successfully.\")\n",
    "#         else:\n",
    "#             logging.warning(\"Alert email was triggered but may not have been sent to all recipients.\")\n",
    "#         return success\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Email trigger failed: {e}\")\n",
    "#         return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02c65d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \n",
      "--- Model Evaluation ---\n",
      "[INFO] Summary saved to SCAM.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       306\n",
      "           1     1.0000    1.0000    1.0000        39\n",
      "\n",
      "    accuracy                         1.0000       345\n",
      "   macro avg     1.0000    1.0000    1.0000       345\n",
      "weighted avg     1.0000    1.0000    1.0000       345\n",
      "\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(RAW_CSV):\n",
    "        raise FileNotFoundError(f\"{RAW_CSV} not found!\")\n",
    "\n",
    "    df_raw = pd.read_csv(RAW_CSV, header=None)\n",
    "    df_raw.columns = [\n",
    "        'timestamp', 'src_ip', 'dst_ip',\n",
    "        'src_port', 'dst_port', 'protocol',\n",
    "        'flags', 'length', 'ttl', 'window_size', 'label'\n",
    "    ]\n",
    "\n",
    "    df_clean = clean_dataframe(df_raw)\n",
    "    model = train_model(df_clean)\n",
    "    summary = analyze_and_export(df_clean, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0717cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### end of ` network_traffic_analysis.py` #####\n",
    "# tata bye bye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038c042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
